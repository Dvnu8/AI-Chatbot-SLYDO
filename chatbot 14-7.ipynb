{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c420ae96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Deven\\AppData\\Local\\Temp\\ipykernel_56224\\1391222901.py:220: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chat = gr.Chatbot(label=\"üí¨ Riwayat Percakapan\", height=400)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'gradio' has no attribute 'blocks'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 245\u001b[39m\n\u001b[32m    242\u001b[39m     file_upload.change(process_file_upload, inputs=file_upload, outputs=[filename_box, gallery])\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m     \u001b[43mdemo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Deven\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\gradio\\blocks.py:2870\u001b[39m, in \u001b[36mBlocks.launch\u001b[39m\u001b[34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, share_server_tls_certificate, auth_dependency, max_file_size, enable_monitoring, strict_cors, node_server_name, node_port, ssr_mode, pwa, _frontend)\u001b[39m\n\u001b[32m   2862\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33manalytics_enabled\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   2863\u001b[39m     data = {\n\u001b[32m   2864\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlaunch_method\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mbrowser\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inbrowser \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minline\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2865\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mis_google_colab\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.is_colab,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2868\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.mode,\n\u001b[32m   2869\u001b[39m     }\n\u001b[32m-> \u001b[39m\u001b[32m2870\u001b[39m     \u001b[43manalytics\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlaunched_analytics\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2872\u001b[39m is_in_interactive_mode = \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(sys, \u001b[33m\"\u001b[39m\u001b[33mps1\u001b[39m\u001b[33m\"\u001b[39m, sys.flags.interactive))\n\u001b[32m   2874\u001b[39m \u001b[38;5;66;03m# Block main thread if debug==True\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Deven\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\gradio\\analytics.py:176\u001b[39m, in \u001b[36mlaunched_analytics\u001b[39m\u001b[34m(blocks, data)\u001b[39m\n\u001b[32m    173\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [b.get_block_name() \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m components] \u001b[38;5;28;01mif\u001b[39;00m components \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fallback\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m core_components = [get_block_name(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcore_gradio_components\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m    178\u001b[39m additional_data = {\n\u001b[32m    179\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mversion\u001b[39m\u001b[33m\"\u001b[39m: get_package_version(),\n\u001b[32m    180\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mis_hosted_notebook\u001b[39m\u001b[33m\"\u001b[39m: blocks.is_hosted_notebook,\n\u001b[32m   (...)\u001b[39m\u001b[32m    192\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mis_wasm\u001b[39m\u001b[33m\"\u001b[39m: wasm_utils.IS_WASM,\n\u001b[32m    193\u001b[39m }\n\u001b[32m    194\u001b[39m custom_components = [b \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m blocks_telemetry \u001b[38;5;28;01mif\u001b[39;00m b \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m core_components]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Deven\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\gradio\\utils.py:641\u001b[39m, in \u001b[36mcore_gradio_components\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcore_gradio_components\u001b[39m():\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    640\u001b[39m         class_\n\u001b[32m--> \u001b[39m\u001b[32m641\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m class_ \u001b[38;5;129;01min\u001b[39;00m \u001b[43mget_all_components\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    642\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m class_.\u001b[34m__module__\u001b[39m.startswith(\u001b[33m\"\u001b[39m\u001b[33mgradio.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    643\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Deven\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\gradio\\utils.py:615\u001b[39m, in \u001b[36mget_all_components\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    610\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_all_components\u001b[39m() -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtype\u001b[39m[Component] | \u001b[38;5;28mtype\u001b[39m[BlockContext]]:\n\u001b[32m    611\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgradio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgr\u001b[39;00m\n\u001b[32m    613\u001b[39m     classes_to_check = (\n\u001b[32m    614\u001b[39m         gr.components.Component.__subclasses__()\n\u001b[32m--> \u001b[39m\u001b[32m615\u001b[39m         + \u001b[43mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mblocks\u001b[49m.BlockContext.__subclasses__()  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    616\u001b[39m     )\n\u001b[32m    617\u001b[39m     subclasses = []\n\u001b[32m    619\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m classes_to_check:\n",
      "\u001b[31mAttributeError\u001b[39m: module 'gradio' has no attribute 'blocks'"
     ]
    }
   ],
   "source": [
    "import os, uuid, shutil, subprocess, requests, re\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import gradio as gr\n",
    "\n",
    "from docx import Document\n",
    "from pptx import Presentation\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "# --------------------------------------\n",
    "# Konfigurasi Path\n",
    "# --------------------------------------\n",
    "OUTPUT_FOLDER = \"output\"\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "POPPLER_PATH = r\"C:\\github\\AI Chatbot SLYDO\\poppler\\poppler-24.08.0\\Library\\bin\"\n",
    "LIBREOFFICE_PATH = r\"C:\\Program Files\\LibreOffice\\program\\soffice.exe\"\n",
    "\n",
    "# --------------------------------------\n",
    "# Ekstraksi PPTX ‚Üí PDF ‚Üí Gambar\n",
    "# --------------------------------------\n",
    "def process_pptx(ppt_path):\n",
    "    try:\n",
    "        # Convert PPTX ke PDF\n",
    "        pdf_path = os.path.splitext(ppt_path)[0] + \".pdf\"\n",
    "        subprocess.run([\n",
    "            LIBREOFFICE_PATH,\n",
    "            \"--headless\", \"--convert-to\", \"pdf\", ppt_path,\n",
    "            \"--outdir\", os.path.dirname(ppt_path)\n",
    "        ], check=True)\n",
    "\n",
    "        # Convert PDF ke gambar\n",
    "        images = convert_from_path(pdf_path, dpi=150, poppler_path=POPPLER_PATH)\n",
    "        image_paths = []\n",
    "        for i, img in enumerate(images):\n",
    "            img_path = os.path.join(OUTPUT_FOLDER, f\"ppt_slide_{i+1}.png\")\n",
    "            img.save(img_path, \"PNG\")\n",
    "            image_paths.append(img_path)\n",
    "\n",
    "        # Ekstraksi teks dari slide\n",
    "        prs = Presentation(ppt_path)\n",
    "        text_content = []\n",
    "        for i, slide in enumerate(prs.slides):\n",
    "            slide_text = f\"[SLIDE {i+1}]\\n\"\n",
    "            for shape in slide.shapes:\n",
    "                if hasattr(shape, \"text\"):\n",
    "                    slide_text += shape.text.strip() + \"\\n\"\n",
    "            text_content.append(slide_text.strip())\n",
    "\n",
    "        return \"\\n\\n\".join(text_content), image_paths\n",
    "    except Exception as e:\n",
    "        return f\"[ERROR PPTX] {str(e)}\", []\n",
    "\n",
    "# --------------------------------------\n",
    "# Ekstraksi PDF\n",
    "# --------------------------------------\n",
    "def process_pdf(pdf_path):\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path, dpi=150, poppler_path=POPPLER_PATH)\n",
    "        image_paths = []\n",
    "        for i, img in enumerate(images):\n",
    "            img_path = os.path.join(OUTPUT_FOLDER, f\"pdf_page_{i+1}.png\")\n",
    "            img.save(img_path, \"PNG\")\n",
    "            image_paths.append(img_path)\n",
    "        return \"[PDF CONTENT]\\n(Slide tidak memiliki teks terstruktur)\", image_paths\n",
    "    except Exception as e:\n",
    "        return f\"[ERROR PDF] {str(e)}\", []\n",
    "\n",
    "# --------------------------------------\n",
    "# Ekstraksi DOCX\n",
    "# --------------------------------------\n",
    "def process_docx(docx_path):\n",
    "    try:\n",
    "        doc = Document(docx_path)\n",
    "        text_content = \"[DOCX CONTENT]\\n\" + \"\\n\".join([p.text for p in doc.paragraphs if p.text.strip()])\n",
    "        preview = os.path.join(OUTPUT_FOLDER, \"docx_preview.png\")\n",
    "        Image.new(\"RGB\", (400, 300), color=(240, 240, 240)).save(preview)\n",
    "        return text_content, [preview]\n",
    "    except Exception as e:\n",
    "        return f\"[ERROR DOCX] {str(e)}\", []\n",
    "\n",
    "# --------------------------------------\n",
    "# Routing Ekstraksi\n",
    "# --------------------------------------\n",
    "def process_file_upload(file_path, progress=gr.Progress()):\n",
    "    ext = os.path.splitext(file_path)[-1].lower()\n",
    "    local_path = os.path.join(OUTPUT_FOLDER, f\"{uuid.uuid4()}_{os.path.basename(file_path)}\")\n",
    "    shutil.copy(file_path, local_path)\n",
    "\n",
    "    if ext == \".pptx\":\n",
    "        content, images = process_pptx(local_path)\n",
    "    elif ext == \".pdf\":\n",
    "        content, images = process_pdf(local_path)\n",
    "    elif ext == \".docx\":\n",
    "        content, images = process_docx(local_path)\n",
    "    else:\n",
    "        return \"‚ùå Format tidak didukung\", []\n",
    "\n",
    "    with open(os.path.join(OUTPUT_FOLDER, \"ExtractedText.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "    return os.path.basename(file_path), images\n",
    "\n",
    "# --------------------------------------\n",
    "# Ambil Chunk Relevan\n",
    "# --------------------------------------\n",
    "def get_relevant_chunks(prompt, full_content):\n",
    "    chunks = full_content.split(\"[SLIDE \")\n",
    "    relevant = []\n",
    "    if \"slide\" in prompt.lower():\n",
    "        nums = re.findall(r'slide\\s*(\\d+)', prompt.lower())\n",
    "        for num in nums:\n",
    "            for chunk in chunks:\n",
    "                if chunk.strip().startswith(num):\n",
    "                    relevant.append(\"[SLIDE \" + chunk.strip())\n",
    "    elif \"[PDF CONTENT]\" in full_content or \"[DOCX CONTENT]\" in full_content:\n",
    "        relevant = [full_content]\n",
    "    else:\n",
    "        relevant = [\"[SLIDE \" + c.strip() for c in chunks[1:4]]\n",
    "    return \"\\n\\n\".join(relevant)\n",
    "\n",
    "# --------------------------------------\n",
    "# Chatbot LLM\n",
    "# --------------------------------------\n",
    "def chatbot_response(prompt, full_content):\n",
    "    relevant = get_relevant_chunks(prompt, full_content)\n",
    "    try:\n",
    "        res = requests.post(\n",
    "            \"https://openrouter.ai/api/v1/chat/completions\",\n",
    "            headers={\n",
    "                \"Authorization\": \"Bearer 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\",\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            },\n",
    "            json={\n",
    "                \"model\": \"deepseek/deepseek-r1:free\",\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"Anda asisten AI yang membantu memahami isi dokumen.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Isi dokumen:\\n{relevant}\\n\\nPertanyaan: {prompt}\"}\n",
    "                ]\n",
    "            },\n",
    "            timeout=40\n",
    "        )\n",
    "        return res.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error: {str(e)}\"\n",
    "\n",
    "# --------------------------------------\n",
    "# TTS\n",
    "# --------------------------------------\n",
    "def speak(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# --------------------------------------\n",
    "# Voice Input\n",
    "# --------------------------------------\n",
    "def recognize_speech():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        audio = r.listen(source)\n",
    "    try:\n",
    "        return \"üéôÔ∏è\", r.recognize_google(audio, language=\"id-ID\")\n",
    "    except:\n",
    "        return \"‚ö†Ô∏è\", \"Tidak dapat mengenali suara.\"\n",
    "\n",
    "# --------------------------------------\n",
    "# Template Prompt\n",
    "# --------------------------------------\n",
    "def fill_prompt_template(name):\n",
    "    templates = {\n",
    "        \"Ringkasan\": \"Buat ringkasan singkat dari dokumen ini.\",\n",
    "        \"Penjelasan Slide\": \"Jelaskan isi dari slide 3.\",\n",
    "        \"Pertanyaan Latihan\": \"Buat 3 soal latihan dari materi ini.\",\n",
    "        \"Makna Gambar\": \"Jelaskan makna gambar pada slide atau halaman.\",\n",
    "        \"Interpretasi Data\": \"Apa interpretasi dari grafik atau data yang ditampilkan?\"\n",
    "    }\n",
    "    return templates.get(name, \"\")\n",
    "\n",
    "# --------------------------------------\n",
    "# Chat Interface\n",
    "# --------------------------------------\n",
    "def chat_interface(history, user_input, tts_enabled, history_state):\n",
    "    text_file = os.path.join(OUTPUT_FOLDER, \"ExtractedText.txt\")\n",
    "    if not os.path.exists(text_file):\n",
    "        return history + [(user_input, \"‚ùóSilakan unggah file terlebih dahulu.\")], history_state, gr.update(choices=[q for q, _ in history_state])\n",
    "\n",
    "    with open(text_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    response = chatbot_response(user_input, content)\n",
    "    if tts_enabled:\n",
    "        speak(response)\n",
    "\n",
    "    history.append((user_input, response))\n",
    "    history_state.append((user_input, response))\n",
    "    return history, history_state, gr.update(choices=[q for q, _ in history_state])\n",
    "\n",
    "def restore_question_from_history(selected_question, history_state):\n",
    "    for q, _ in history_state:\n",
    "        if q == selected_question:\n",
    "            return q\n",
    "    return \"\"\n",
    "\n",
    "# --------------------------------------\n",
    "# Gradio UI\n",
    "# --------------------------------------\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"# ü§ñ SLYDO: Smart Learning Document Chatbot\\nUnggah dokumen dan tanyakan apa saja berdasarkan kontennya!\")\n",
    "\n",
    "    history_state = gr.State([])\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            file_upload = gr.File(label=\"üìÇ Unggah File (.pptx, .pdf, .docx)\", file_types=[\".pptx\", \".pdf\", \".docx\"], type=\"filepath\")\n",
    "            filename_box = gr.Textbox(label=\"üìÑ Nama File\", interactive=False)\n",
    "            gallery = gr.Gallery(label=\"üì∏ Preview Dokumen\", height=300, columns=1)\n",
    "\n",
    "        with gr.Column(scale=2):\n",
    "            chat = gr.Chatbot(label=\"üí¨ Riwayat Percakapan\", height=400)\n",
    "            user_input = gr.Textbox(label=\"üìù Pertanyaan Anda\")\n",
    "            tts_toggle = gr.Checkbox(label=\"üîà Aktifkan Suara\", value=True)\n",
    "\n",
    "            history_dropdown = gr.Dropdown(label=\"üïò Riwayat Pertanyaan\", choices=[], interactive=True)\n",
    "            history_dropdown.change(restore_question_from_history, inputs=[history_dropdown, history_state], outputs=user_input)\n",
    "\n",
    "            with gr.Row():\n",
    "                voice_btn = gr.Button(\"üé§ Tanya dengan Suara\")\n",
    "                send_btn = gr.Button(\"üì® Kirim Pertanyaan\")\n",
    "\n",
    "            send_btn.click(chat_interface, inputs=[chat, user_input, tts_toggle, history_state], outputs=[chat, history_state, history_dropdown])\n",
    "            voice_btn.click(recognize_speech, outputs=[user_input, user_input])\n",
    "\n",
    "            gr.Markdown(\"### üîé Prompt Cepat\")\n",
    "            with gr.Row():\n",
    "                gr.Button(\"üìã Ringkasan\").click(lambda: fill_prompt_template(\"Ringkasan\"), outputs=user_input)\n",
    "                gr.Button(\"üîç Penjelasan Slide\").click(lambda: fill_prompt_template(\"Penjelasan Slide\"), outputs=user_input)\n",
    "                gr.Button(\"‚ùì Pertanyaan\").click(lambda: fill_prompt_template(\"Pertanyaan Latihan\"), outputs=user_input)\n",
    "                gr.Button(\"üñºÔ∏è Makna Gambar\").click(lambda: fill_prompt_template(\"Makna Gambar\"), outputs=user_input)\n",
    "                gr.Button(\"üìä Interpretasi Data\").click(lambda: fill_prompt_template(\"Interpretasi Data\"), outputs=user_input)\n",
    "\n",
    "    file_upload.change(process_file_upload, inputs=file_upload, outputs=[filename_box, gallery])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
